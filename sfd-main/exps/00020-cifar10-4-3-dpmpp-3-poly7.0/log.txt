Model already exists: ../sfd-main/src/cifar10/edm-cifar10-32x32-uncond-vp.pkl
Loading the pre-trained diffusion model from "../sfd-main/src/cifar10/edm-cifar10-32x32-uncond-vp.pkl"...
/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
Total parameters in U-Net:      60396419
Setting up optimizer...
Training for 200 kimg...

Step: 0 | Loss-mean: 1132.80761719 | loss-std:  14.57671833
Step: 1 | Loss-mean: 131.49717712 | loss-std:   1.66936827
Step: 2 | Loss-mean:  26.95491791 | loss-std:   6.40840054
tick 0     kimg 0.3       time 23s          sec/tick 18.8    sec/kimg 73.31   maintenance 4.6    gpumem 20.10  reserved 20.44 
Step: 0 | Loss-mean: 1135.32458496 | loss-std:  13.99360275
Step: 1 | Loss-mean: 131.73260498 | loss-std:   1.58915854
Step: 2 | Loss-mean:  27.88724518 | loss-std:   6.61558962
Step: 0 | Loss-mean: 1133.76892090 | loss-std:  14.65522099
Step: 1 | Loss-mean: 131.47787476 | loss-std:   1.67980230
Step: 2 | Loss-mean:  28.18424797 | loss-std:   6.48405695
Step: 0 | Loss-mean: 1135.07446289 | loss-std:  14.53809547
Step: 1 | Loss-mean: 131.60491943 | loss-std:   1.67584968
Step: 2 | Loss-mean:  28.08329391 | loss-std:   6.96455956
Step: 0 | Loss-mean: 1134.35498047 | loss-std:  14.89406300
Step: 1 | Loss-mean: 131.44960022 | loss-std:   1.71123028
Step: 2 | Loss-mean:  27.72260666 | loss-std:   6.51054955
tick 1     kimg 1.3       time 1m 03s       sec/tick 39.5    sec/kimg 38.62   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1134.94653320 | loss-std:  15.60455418
Step: 1 | Loss-mean: 131.46347046 | loss-std:   1.81795704
Step: 2 | Loss-mean:  28.32656097 | loss-std:   7.03829908
Step: 0 | Loss-mean: 1135.03112793 | loss-std:  15.04879570
Step: 1 | Loss-mean: 131.43002319 | loss-std:   1.70549834
Step: 2 | Loss-mean:  26.77258110 | loss-std:   6.67453814
Step: 0 | Loss-mean: 1133.51318359 | loss-std:  13.90177631
Step: 1 | Loss-mean: 131.15620422 | loss-std:   1.62105525
Step: 2 | Loss-mean:  28.68020248 | loss-std:   6.90009975
Step: 0 | Loss-mean: 1133.33410645 | loss-std:  14.86070061
Step: 1 | Loss-mean: 131.11840820 | loss-std:   1.70270932
Step: 2 | Loss-mean:  28.49397278 | loss-std:   6.85810041
tick 2     kimg 2.3       time 1m 43s       sec/tick 40.1    sec/kimg 39.19   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1134.04614258 | loss-std:  14.04507923
Step: 1 | Loss-mean: 131.12918091 | loss-std:   1.58385992
Step: 2 | Loss-mean:  27.80882263 | loss-std:   6.59294558
Step: 0 | Loss-mean: 1134.56323242 | loss-std:  14.55364513
Step: 1 | Loss-mean: 131.11177063 | loss-std:   1.66443980
Step: 2 | Loss-mean:  28.34338188 | loss-std:   6.26934862
Step: 0 | Loss-mean: 1132.30493164 | loss-std:  14.26792240
Step: 1 | Loss-mean: 130.80374146 | loss-std:   1.65617192
Step: 2 | Loss-mean:  27.62161636 | loss-std:   6.46193647
Step: 0 | Loss-mean: 1133.44750977 | loss-std:  13.39238071
Step: 1 | Loss-mean: 130.88525391 | loss-std:   1.55181086
Step: 2 | Loss-mean:  27.32272339 | loss-std:   6.53861904
tick 3     kimg 3.3       time 2m 24s       sec/tick 40.9    sec/kimg 39.91   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1134.05310059 | loss-std:  14.66395187
Step: 1 | Loss-mean: 130.89816284 | loss-std:   1.71640539
Step: 2 | Loss-mean:  27.88385391 | loss-std:   6.62576675
Step: 0 | Loss-mean: 1133.55090332 | loss-std:  14.70960522
Step: 1 | Loss-mean: 130.80645752 | loss-std:   1.69178259
Step: 2 | Loss-mean:  26.92045975 | loss-std:   7.18730783
Step: 0 | Loss-mean: 1134.71093750 | loss-std:  14.35500717
Step: 1 | Loss-mean: 130.84295654 | loss-std:   1.63347197
Step: 2 | Loss-mean:  27.91244507 | loss-std:   6.42396402
Step: 0 | Loss-mean: 1132.73657227 | loss-std:  15.45950317
Step: 1 | Loss-mean: 130.59080505 | loss-std:   1.78794563
Step: 2 | Loss-mean:  27.44701004 | loss-std:   6.92018700
tick 4     kimg 4.4       time 3m 05s       sec/tick 40.7    sec/kimg 39.77   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1134.46350098 | loss-std:  13.77415180
Step: 1 | Loss-mean: 130.72195435 | loss-std:   1.57818878
Step: 2 | Loss-mean:  27.31853676 | loss-std:   6.55207396
Step: 0 | Loss-mean: 1132.51989746 | loss-std:  15.20342445
Step: 1 | Loss-mean: 130.44648743 | loss-std:   1.74888325
Step: 2 | Loss-mean:  28.16590881 | loss-std:   6.83043432
Step: 0 | Loss-mean: 1133.97216797 | loss-std:  14.16417503
Step: 1 | Loss-mean: 130.59124756 | loss-std:   1.62201440
Step: 2 | Loss-mean:  27.97767258 | loss-std:   6.95793629
Step: 0 | Loss-mean: 1132.64624023 | loss-std:  14.66043091
Step: 1 | Loss-mean: 130.35003662 | loss-std:   1.69032776
Step: 2 | Loss-mean:  27.05951691 | loss-std:   7.02060080
tick 5     kimg 5.4       time 3m 45s       sec/tick 40.7    sec/kimg 39.71   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1133.58728027 | loss-std:  14.03369522
Step: 1 | Loss-mean: 130.38471985 | loss-std:   1.61653638
Step: 2 | Loss-mean:  27.71794891 | loss-std:   6.71994400
Step: 0 | Loss-mean: 1132.23950195 | loss-std:  13.66163921
Step: 1 | Loss-mean: 130.19636536 | loss-std:   1.55036175
Step: 2 | Loss-mean:  27.59751701 | loss-std:   7.29383612
Step: 0 | Loss-mean: 1132.64172363 | loss-std:  13.92732430
Step: 1 | Loss-mean: 130.13858032 | loss-std:   1.59320617
Step: 2 | Loss-mean:  26.60808945 | loss-std:   6.66005802
Step: 0 | Loss-mean: 1129.59570312 | loss-std:  14.62980747
Step: 1 | Loss-mean: 129.75549316 | loss-std:   1.68017471
Step: 2 | Loss-mean:  27.21438217 | loss-std:   7.09751177
tick 6     kimg 6.4       time 4m 26s       sec/tick 40.8    sec/kimg 39.84   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1132.94506836 | loss-std:  13.83727455
Step: 1 | Loss-mean: 130.02032471 | loss-std:   1.60708654
Step: 2 | Loss-mean:  26.79766083 | loss-std:   6.70841026
Step: 0 | Loss-mean: 1132.92407227 | loss-std:  14.11416912
Step: 1 | Loss-mean: 129.99807739 | loss-std:   1.63397264
Step: 2 | Loss-mean:  26.75758743 | loss-std:   6.74462414
Step: 0 | Loss-mean: 1132.50024414 | loss-std:  13.40979195
Step: 1 | Loss-mean: 129.80886841 | loss-std:   1.49571478
Step: 2 | Loss-mean:  26.96485138 | loss-std:   6.92298317
Step: 0 | Loss-mean: 1133.10546875 | loss-std:  13.44489861
Step: 1 | Loss-mean: 129.73968506 | loss-std:   1.53072572
Step: 2 | Loss-mean:  26.56290436 | loss-std:   6.32126951
tick 7     kimg 7.4       time 5m 07s       sec/tick 40.8    sec/kimg 39.83   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1130.34545898 | loss-std:  14.49874020
Step: 1 | Loss-mean: 129.34237671 | loss-std:   1.65464795
Step: 2 | Loss-mean:  26.21448898 | loss-std:   6.20962524
Step: 0 | Loss-mean: 1133.82141113 | loss-std:  14.08889389
Step: 1 | Loss-mean: 129.68426514 | loss-std:   1.62165046
Step: 2 | Loss-mean:  25.66627121 | loss-std:   7.04956198
Step: 0 | Loss-mean: 1131.86743164 | loss-std:  13.78825188
Step: 1 | Loss-mean: 129.31314087 | loss-std:   1.58183360
Step: 2 | Loss-mean:  25.38779449 | loss-std:   6.56724262
Step: 0 | Loss-mean: 1130.98474121 | loss-std:  14.00624371
Step: 1 | Loss-mean: 129.10202026 | loss-std:   1.60678387
Step: 2 | Loss-mean:  25.62965965 | loss-std:   6.96538639
tick 8     kimg 8.4       time 5m 48s       sec/tick 40.7    sec/kimg 39.76   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1131.77795410 | loss-std:  14.45864964
Step: 1 | Loss-mean: 129.07003784 | loss-std:   1.66111982
Step: 2 | Loss-mean:  25.78190231 | loss-std:   6.36847830
Step: 0 | Loss-mean: 1131.19189453 | loss-std:  14.68146038
Step: 1 | Loss-mean: 128.82110596 | loss-std:   1.65694559
Step: 2 | Loss-mean:  25.40140915 | loss-std:   6.73067951
Step: 0 | Loss-mean: 1130.04809570 | loss-std:  14.41975117
Step: 1 | Loss-mean: 128.60394287 | loss-std:   1.65035832
Step: 2 | Loss-mean:  24.46200562 | loss-std:   6.87537098
Step: 0 | Loss-mean: 1130.21801758 | loss-std:  14.35521603
Step: 1 | Loss-mean: 128.46105957 | loss-std:   1.64627576
Step: 2 | Loss-mean:  23.95293045 | loss-std:   6.37932920
tick 9     kimg 9.5       time 6m 28s       sec/tick 40.8    sec/kimg 39.80   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean: 1132.32543945 | loss-std:  14.51505375
Step: 1 | Loss-mean: 128.51202393 | loss-std:   1.61081958
Step: 2 | Loss-mean:  23.84072495 | loss-std:   6.21401978
Step: 0 | Loss-mean: 1131.40966797 | loss-std:  14.91227436
Step: 1 | Loss-mean: 128.29092407 | loss-std:   1.66326833
Step: 2 | Loss-mean:  24.46814156 | loss-std:   7.31758642
Step: 0 | Loss-mean: 1131.45483398 | loss-std:  14.42147827
Step: 1 | Loss-mean: 128.12124634 | loss-std:   1.65176046
Step: 2 | Loss-mean:  23.23493576 | loss-std:   6.48004913
Step: 0 | Loss-mean: 1130.38281250 | loss-std:  13.20437050
Step: 1 | Loss-mean: 127.80217743 | loss-std:   1.50124454
Step: 2 | Loss-mean:  23.23783493 | loss-std:   5.78017426
tick 10    kimg 10.5      time 7m 09s       sec/tick 40.8    sec/kimg 39.80   maintenance 0.0    gpumem 16.65  reserved 17.15 
Step: 0 | Loss-mean:          nan | loss-std:          nan
Step: 1 | Loss-mean:          nan | loss-std:          nan
Step: 2 | Loss-mean:          nan | loss-std:          nan
Meet nan, disable fp16!
[rank0]: Traceback (most recent call last):
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/train.py", line 155, in <module>
[rank0]:     main()
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/click/core.py", line 1161, in __call__
[rank0]:     return self.main(*args, **kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/click/core.py", line 1082, in main
[rank0]:     rv = self.invoke(ctx)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/click/core.py", line 1443, in invoke
[rank0]:     return ctx.invoke(self.callback, **ctx.params)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/click/core.py", line 788, in invoke
[rank0]:     return __callback(*args, **kwargs)
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/train.py", line 150, in main
[rank0]:     training_loop.training_loop(**c)
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/training/training_loop.py", line 303, in training_loop
[rank0]:     loss, stu_out = loss_fn(net=ddp, tensor_in=latents[round_idx], labels=labels[round_idx], step_idx=step_idx, teacher_out=teacher_traj[round_idx][start:end])                        
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/training/loss.py", line 70, in __call__
[rank0]:     student_out, _, _ = self.solver_stu(
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/solvers.py", line 90, in euler_sampler_multistep
[rank0]:     denoised_multistep = get_denoised(
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/solvers.py", line 15, in get_denoised
[rank0]:     denoised = net(x, t, class_labels=class_labels, step_condition=step_condition)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/models/networks_edm.py", line 570, in forward
[rank0]:     F_x = self.model(c_in * x, c_noise.flatten(), class_labels=class_labels, step_condition=step_condition, **model_kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/models/networks_edm.py", line 400, in forward
[rank0]:     x = block(x, emb, emb_step)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/teamspace/studios/this_studio/sfd-main/models/networks_edm.py", line 168, in forward
[rank0]:     x = self.conv0(silu(self.norm0(x)))
[rank0]:   File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/nn/functional.py", line 2380, in silu
[rank0]:     return torch._C._nn.silu(input)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 21.96 GiB of which 363.06 MiB is free. Process 11641 has 21.60 GiB memory in use. Of the allocated memory 19.45 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
