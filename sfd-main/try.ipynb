{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0b947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29219262500085036, 0.29925915221060156, 0.338998035774447, 1.0]\n"
     ]
    }
   ],
   "source": [
    "a =  0.4420450177378683\n",
    "b = 0.010690629668597906\n",
    "c = 0.060119161083589945\n",
    "\n",
    "x = a + b + c + 1.0\n",
    "w1 = a / x\n",
    "w2 = (a + b) / x\n",
    "w3 = (a + b + c) / x\n",
    "w4 = 1.0\n",
    "weights = [w1, w2, w3, w4]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388cfc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Step-2 loss 4.244495 occurred at iteration index 1133\n"
     ]
    }
   ],
   "source": [
    "# assume you already have step_2_losses from your find_min_s2_loss logic\n",
    "# e.g.:\n",
    "import re\n",
    "\n",
    "log_path = '/home/cherish/SADD/sfd-main/exps/00054-cifar10-4-3-dpmpp-3-poly7.0/log.txt'\n",
    "all_losses = [[] for _ in range(3)]\n",
    "pattern = re.compile(r\"Step:\\s*(\\d+)\\s*\\|\\s*Loss-mean:\\s*([0-9]+\\.[0-9]+)\")\n",
    "with open(log_path, 'r') as f:\n",
    "    for line in f:\n",
    "        m = pattern.search(line)\n",
    "        if m:\n",
    "            step = int(m.group(1))\n",
    "            loss = float(m.group(2))\n",
    "            if 0 <= step < 3:\n",
    "                all_losses[step].append(loss)\n",
    "\n",
    "step_2_losses = all_losses[2]\n",
    "\n",
    "# now find the min and its iteration index\n",
    "min_loss = min(step_2_losses)\n",
    "min_iter = step_2_losses.index(min_loss)\n",
    "print(f\"Min Step-2 loss {min_loss:.6f} occurred at iteration index {min_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98858f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.24449539"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_min_s2_loss(\"/home/cherish/SADD/sfd-main/exps/00054-cifar10-4-3-dpmpp-3-poly7.0/log.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7d25ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_s2_loss(log_path: str) -> float:\n",
    "    \"\"\"\n",
    "    Parse the log file to extract all Step 2 Loss_ls-3-mean values\n",
    "    and return their minimum.\n",
    "    \"\"\"\n",
    "    \n",
    "    step2_losses = []\n",
    "    \n",
    "    # Pattern to match Step 2 Loss_ls-3-mean lines\n",
    "    step2_loss_pattern = re.compile(r\"Step:\\s*2\\s*\\|\\s*Loss-mean:\\s*([0-9]+\\.[0-9]+)\")\n",
    "\n",
    "    \n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = step2_loss_pattern.search(line)\n",
    "            if match:\n",
    "                loss_value = float(match.group(1))\n",
    "                step2_losses.append(loss_value)\n",
    "                # print(f\"Found Step 2 Loss_ls-3-mean: {loss_value}\")\n",
    "    \n",
    "    if not step2_losses:\n",
    "        raise ValueError(\"No Step 2 Loss_ls-3-mean values found\")\n",
    "    \n",
    "    min_loss = min(step2_losses)\n",
    "    # print(f\"\\nAll Step 2 Loss_ls-3-mean values: {step2_ls3_losses}\")\n",
    "    # print(f\"Total count: {len(step2_ls3_losses)}\")\n",
    "    # print(f\"Minimum Step 2 Loss_ls-3-mean: {min_loss}\")\n",
    "    \n",
    "    return min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf837064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.69043016"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "find_min_s2_loss(\"/teamspace/studios/this_studio/sfd-main/training/original_training_logs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da749a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the pickle file: ['ema', 'loss_fn', 'augment_pipe', 'dataset_kwargs']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_path = '/teamspace/studios/this_studio/sfd-main/exps/teacher_model/edm-cifar10-32x32-cond-vp.pkl'  # replace with your .pkl file path\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "if hasattr(data, 'keys'):\n",
    "    print(\"Keys in the pickle file:\", list(data.keys()))\n",
    "else:\n",
    "    print(f\"Loaded object is a {type(data)}, which has no .keys()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef17411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state_dict keys and tensor shapes:\n",
      "map_label.weight: (128, 10)\n",
      "map_label.bias: (128,)\n",
      "map_augment.weight: (128, 9)\n",
      "map_layer0.weight: (512, 128)\n",
      "map_layer0.bias: (512,)\n",
      "map_layer1.weight: (512, 512)\n",
      "map_layer1.bias: (512,)\n",
      "enc.32x32_conv.weight: (128, 3, 3, 3)\n",
      "enc.32x32_conv.bias: (128,)\n",
      "enc.32x32_block0.norm0.weight: (128,)\n",
      "enc.32x32_block0.norm0.bias: (128,)\n",
      "enc.32x32_block0.conv0.weight: (256, 128, 3, 3)\n",
      "enc.32x32_block0.conv0.bias: (256,)\n",
      "enc.32x32_block0.affine.weight: (256, 512)\n",
      "enc.32x32_block0.affine.bias: (256,)\n",
      "enc.32x32_block0.norm1.weight: (256,)\n",
      "enc.32x32_block0.norm1.bias: (256,)\n",
      "enc.32x32_block0.conv1.weight: (256, 256, 3, 3)\n",
      "enc.32x32_block0.conv1.bias: (256,)\n",
      "enc.32x32_block0.skip.weight: (256, 128, 1, 1)\n",
      "enc.32x32_block0.skip.bias: (256,)\n",
      "enc.32x32_block1.norm0.weight: (256,)\n",
      "enc.32x32_block1.norm0.bias: (256,)\n",
      "enc.32x32_block1.conv0.weight: (256, 256, 3, 3)\n",
      "enc.32x32_block1.conv0.bias: (256,)\n",
      "enc.32x32_block1.affine.weight: (256, 512)\n",
      "enc.32x32_block1.affine.bias: (256,)\n",
      "enc.32x32_block1.norm1.weight: (256,)\n",
      "enc.32x32_block1.norm1.bias: (256,)\n",
      "enc.32x32_block1.conv1.weight: (256, 256, 3, 3)\n",
      "enc.32x32_block1.conv1.bias: (256,)\n",
      "enc.32x32_block2.norm0.weight: (256,)\n",
      "enc.32x32_block2.norm0.bias: (256,)\n",
      "enc.32x32_block2.conv0.weight: (256, 256, 3, 3)\n",
      "enc.32x32_block2.conv0.bias: (256,)\n",
      "enc.32x32_block2.affine.weight: (256, 512)\n",
      "enc.32x32_block2.affine.bias: (256,)\n",
      "enc.32x32_block2.norm1.weight: (256,)\n",
      "enc.32x32_block2.norm1.bias: (256,)\n",
      "enc.32x32_block2.conv1.weight: (256, 256, 3, 3)\n",
      "enc.32x32_block2.conv1.bias: (256,)\n",
      "enc.32x32_block3.norm0.weight: (256,)\n",
      "enc.32x32_block3.norm0.bias: (256,)\n",
      "enc.32x32_block3.conv0.weight: (256, 256, 3, 3)\n",
      "enc.32x32_block3.conv0.bias: (256,)\n",
      "enc.32x32_block3.affine.weight: (256, 512)\n",
      "enc.32x32_block3.affine.bias: (256,)\n",
      "enc.32x32_block3.norm1.weight: (256,)\n",
      "enc.32x32_block3.norm1.bias: (256,)\n",
      "enc.32x32_block3.conv1.weight: (256, 256, 3, 3)\n",
      "enc.32x32_block3.conv1.bias: (256,)\n",
      "enc.16x16_down.norm0.weight: (256,)\n",
      "enc.16x16_down.norm0.bias: (256,)\n",
      "enc.16x16_down.conv0.weight: (256, 256, 3, 3)\n",
      "enc.16x16_down.conv0.bias: (256,)\n",
      "enc.16x16_down.conv0.resample_filter: (1, 1, 2, 2)\n",
      "enc.16x16_down.affine.weight: (256, 512)\n",
      "enc.16x16_down.affine.bias: (256,)\n",
      "enc.16x16_down.norm1.weight: (256,)\n",
      "enc.16x16_down.norm1.bias: (256,)\n",
      "enc.16x16_down.conv1.weight: (256, 256, 3, 3)\n",
      "enc.16x16_down.conv1.bias: (256,)\n",
      "enc.16x16_down.skip.weight: (256, 256, 1, 1)\n",
      "enc.16x16_down.skip.bias: (256,)\n",
      "enc.16x16_down.skip.resample_filter: (1, 1, 2, 2)\n",
      "enc.16x16_block0.norm0.weight: (256,)\n",
      "enc.16x16_block0.norm0.bias: (256,)\n",
      "enc.16x16_block0.conv0.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block0.conv0.bias: (256,)\n",
      "enc.16x16_block0.affine.weight: (256, 512)\n",
      "enc.16x16_block0.affine.bias: (256,)\n",
      "enc.16x16_block0.norm1.weight: (256,)\n",
      "enc.16x16_block0.norm1.bias: (256,)\n",
      "enc.16x16_block0.conv1.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block0.conv1.bias: (256,)\n",
      "enc.16x16_block0.norm2.weight: (256,)\n",
      "enc.16x16_block0.norm2.bias: (256,)\n",
      "enc.16x16_block0.qkv.weight: (768, 256, 1, 1)\n",
      "enc.16x16_block0.qkv.bias: (768,)\n",
      "enc.16x16_block0.proj.weight: (256, 256, 1, 1)\n",
      "enc.16x16_block0.proj.bias: (256,)\n",
      "enc.16x16_block1.norm0.weight: (256,)\n",
      "enc.16x16_block1.norm0.bias: (256,)\n",
      "enc.16x16_block1.conv0.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block1.conv0.bias: (256,)\n",
      "enc.16x16_block1.affine.weight: (256, 512)\n",
      "enc.16x16_block1.affine.bias: (256,)\n",
      "enc.16x16_block1.norm1.weight: (256,)\n",
      "enc.16x16_block1.norm1.bias: (256,)\n",
      "enc.16x16_block1.conv1.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block1.conv1.bias: (256,)\n",
      "enc.16x16_block1.norm2.weight: (256,)\n",
      "enc.16x16_block1.norm2.bias: (256,)\n",
      "enc.16x16_block1.qkv.weight: (768, 256, 1, 1)\n",
      "enc.16x16_block1.qkv.bias: (768,)\n",
      "enc.16x16_block1.proj.weight: (256, 256, 1, 1)\n",
      "enc.16x16_block1.proj.bias: (256,)\n",
      "enc.16x16_block2.norm0.weight: (256,)\n",
      "enc.16x16_block2.norm0.bias: (256,)\n",
      "enc.16x16_block2.conv0.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block2.conv0.bias: (256,)\n",
      "enc.16x16_block2.affine.weight: (256, 512)\n",
      "enc.16x16_block2.affine.bias: (256,)\n",
      "enc.16x16_block2.norm1.weight: (256,)\n",
      "enc.16x16_block2.norm1.bias: (256,)\n",
      "enc.16x16_block2.conv1.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block2.conv1.bias: (256,)\n",
      "enc.16x16_block2.norm2.weight: (256,)\n",
      "enc.16x16_block2.norm2.bias: (256,)\n",
      "enc.16x16_block2.qkv.weight: (768, 256, 1, 1)\n",
      "enc.16x16_block2.qkv.bias: (768,)\n",
      "enc.16x16_block2.proj.weight: (256, 256, 1, 1)\n",
      "enc.16x16_block2.proj.bias: (256,)\n",
      "enc.16x16_block3.norm0.weight: (256,)\n",
      "enc.16x16_block3.norm0.bias: (256,)\n",
      "enc.16x16_block3.conv0.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block3.conv0.bias: (256,)\n",
      "enc.16x16_block3.affine.weight: (256, 512)\n",
      "enc.16x16_block3.affine.bias: (256,)\n",
      "enc.16x16_block3.norm1.weight: (256,)\n",
      "enc.16x16_block3.norm1.bias: (256,)\n",
      "enc.16x16_block3.conv1.weight: (256, 256, 3, 3)\n",
      "enc.16x16_block3.conv1.bias: (256,)\n",
      "enc.16x16_block3.norm2.weight: (256,)\n",
      "enc.16x16_block3.norm2.bias: (256,)\n",
      "enc.16x16_block3.qkv.weight: (768, 256, 1, 1)\n",
      "enc.16x16_block3.qkv.bias: (768,)\n",
      "enc.16x16_block3.proj.weight: (256, 256, 1, 1)\n",
      "enc.16x16_block3.proj.bias: (256,)\n",
      "enc.8x8_down.norm0.weight: (256,)\n",
      "enc.8x8_down.norm0.bias: (256,)\n",
      "enc.8x8_down.conv0.weight: (256, 256, 3, 3)\n",
      "enc.8x8_down.conv0.bias: (256,)\n",
      "enc.8x8_down.conv0.resample_filter: (1, 1, 2, 2)\n",
      "enc.8x8_down.affine.weight: (256, 512)\n",
      "enc.8x8_down.affine.bias: (256,)\n",
      "enc.8x8_down.norm1.weight: (256,)\n",
      "enc.8x8_down.norm1.bias: (256,)\n",
      "enc.8x8_down.conv1.weight: (256, 256, 3, 3)\n",
      "enc.8x8_down.conv1.bias: (256,)\n",
      "enc.8x8_down.skip.weight: (256, 256, 1, 1)\n",
      "enc.8x8_down.skip.bias: (256,)\n",
      "enc.8x8_down.skip.resample_filter: (1, 1, 2, 2)\n",
      "enc.8x8_block0.norm0.weight: (256,)\n",
      "enc.8x8_block0.norm0.bias: (256,)\n",
      "enc.8x8_block0.conv0.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block0.conv0.bias: (256,)\n",
      "enc.8x8_block0.affine.weight: (256, 512)\n",
      "enc.8x8_block0.affine.bias: (256,)\n",
      "enc.8x8_block0.norm1.weight: (256,)\n",
      "enc.8x8_block0.norm1.bias: (256,)\n",
      "enc.8x8_block0.conv1.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block0.conv1.bias: (256,)\n",
      "enc.8x8_block1.norm0.weight: (256,)\n",
      "enc.8x8_block1.norm0.bias: (256,)\n",
      "enc.8x8_block1.conv0.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block1.conv0.bias: (256,)\n",
      "enc.8x8_block1.affine.weight: (256, 512)\n",
      "enc.8x8_block1.affine.bias: (256,)\n",
      "enc.8x8_block1.norm1.weight: (256,)\n",
      "enc.8x8_block1.norm1.bias: (256,)\n",
      "enc.8x8_block1.conv1.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block1.conv1.bias: (256,)\n",
      "enc.8x8_block2.norm0.weight: (256,)\n",
      "enc.8x8_block2.norm0.bias: (256,)\n",
      "enc.8x8_block2.conv0.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block2.conv0.bias: (256,)\n",
      "enc.8x8_block2.affine.weight: (256, 512)\n",
      "enc.8x8_block2.affine.bias: (256,)\n",
      "enc.8x8_block2.norm1.weight: (256,)\n",
      "enc.8x8_block2.norm1.bias: (256,)\n",
      "enc.8x8_block2.conv1.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block2.conv1.bias: (256,)\n",
      "enc.8x8_block3.norm0.weight: (256,)\n",
      "enc.8x8_block3.norm0.bias: (256,)\n",
      "enc.8x8_block3.conv0.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block3.conv0.bias: (256,)\n",
      "enc.8x8_block3.affine.weight: (256, 512)\n",
      "enc.8x8_block3.affine.bias: (256,)\n",
      "enc.8x8_block3.norm1.weight: (256,)\n",
      "enc.8x8_block3.norm1.bias: (256,)\n",
      "enc.8x8_block3.conv1.weight: (256, 256, 3, 3)\n",
      "enc.8x8_block3.conv1.bias: (256,)\n",
      "dec.8x8_in0.norm0.weight: (256,)\n",
      "dec.8x8_in0.norm0.bias: (256,)\n",
      "dec.8x8_in0.conv0.weight: (256, 256, 3, 3)\n",
      "dec.8x8_in0.conv0.bias: (256,)\n",
      "dec.8x8_in0.affine.weight: (256, 512)\n",
      "dec.8x8_in0.affine.bias: (256,)\n",
      "dec.8x8_in0.norm1.weight: (256,)\n",
      "dec.8x8_in0.norm1.bias: (256,)\n",
      "dec.8x8_in0.conv1.weight: (256, 256, 3, 3)\n",
      "dec.8x8_in0.conv1.bias: (256,)\n",
      "dec.8x8_in0.norm2.weight: (256,)\n",
      "dec.8x8_in0.norm2.bias: (256,)\n",
      "dec.8x8_in0.qkv.weight: (768, 256, 1, 1)\n",
      "dec.8x8_in0.qkv.bias: (768,)\n",
      "dec.8x8_in0.proj.weight: (256, 256, 1, 1)\n",
      "dec.8x8_in0.proj.bias: (256,)\n",
      "dec.8x8_in1.norm0.weight: (256,)\n",
      "dec.8x8_in1.norm0.bias: (256,)\n",
      "dec.8x8_in1.conv0.weight: (256, 256, 3, 3)\n",
      "dec.8x8_in1.conv0.bias: (256,)\n",
      "dec.8x8_in1.affine.weight: (256, 512)\n",
      "dec.8x8_in1.affine.bias: (256,)\n",
      "dec.8x8_in1.norm1.weight: (256,)\n",
      "dec.8x8_in1.norm1.bias: (256,)\n",
      "dec.8x8_in1.conv1.weight: (256, 256, 3, 3)\n",
      "dec.8x8_in1.conv1.bias: (256,)\n",
      "dec.8x8_block0.norm0.weight: (512,)\n",
      "dec.8x8_block0.norm0.bias: (512,)\n",
      "dec.8x8_block0.conv0.weight: (256, 512, 3, 3)\n",
      "dec.8x8_block0.conv0.bias: (256,)\n",
      "dec.8x8_block0.affine.weight: (256, 512)\n",
      "dec.8x8_block0.affine.bias: (256,)\n",
      "dec.8x8_block0.norm1.weight: (256,)\n",
      "dec.8x8_block0.norm1.bias: (256,)\n",
      "dec.8x8_block0.conv1.weight: (256, 256, 3, 3)\n",
      "dec.8x8_block0.conv1.bias: (256,)\n",
      "dec.8x8_block0.skip.weight: (256, 512, 1, 1)\n",
      "dec.8x8_block0.skip.bias: (256,)\n",
      "dec.8x8_block1.norm0.weight: (512,)\n",
      "dec.8x8_block1.norm0.bias: (512,)\n",
      "dec.8x8_block1.conv0.weight: (256, 512, 3, 3)\n",
      "dec.8x8_block1.conv0.bias: (256,)\n",
      "dec.8x8_block1.affine.weight: (256, 512)\n",
      "dec.8x8_block1.affine.bias: (256,)\n",
      "dec.8x8_block1.norm1.weight: (256,)\n",
      "dec.8x8_block1.norm1.bias: (256,)\n",
      "dec.8x8_block1.conv1.weight: (256, 256, 3, 3)\n",
      "dec.8x8_block1.conv1.bias: (256,)\n",
      "dec.8x8_block1.skip.weight: (256, 512, 1, 1)\n",
      "dec.8x8_block1.skip.bias: (256,)\n",
      "dec.8x8_block2.norm0.weight: (512,)\n",
      "dec.8x8_block2.norm0.bias: (512,)\n",
      "dec.8x8_block2.conv0.weight: (256, 512, 3, 3)\n",
      "dec.8x8_block2.conv0.bias: (256,)\n",
      "dec.8x8_block2.affine.weight: (256, 512)\n",
      "dec.8x8_block2.affine.bias: (256,)\n",
      "dec.8x8_block2.norm1.weight: (256,)\n",
      "dec.8x8_block2.norm1.bias: (256,)\n",
      "dec.8x8_block2.conv1.weight: (256, 256, 3, 3)\n",
      "dec.8x8_block2.conv1.bias: (256,)\n",
      "dec.8x8_block2.skip.weight: (256, 512, 1, 1)\n",
      "dec.8x8_block2.skip.bias: (256,)\n",
      "dec.8x8_block3.norm0.weight: (512,)\n",
      "dec.8x8_block3.norm0.bias: (512,)\n",
      "dec.8x8_block3.conv0.weight: (256, 512, 3, 3)\n",
      "dec.8x8_block3.conv0.bias: (256,)\n",
      "dec.8x8_block3.affine.weight: (256, 512)\n",
      "dec.8x8_block3.affine.bias: (256,)\n",
      "dec.8x8_block3.norm1.weight: (256,)\n",
      "dec.8x8_block3.norm1.bias: (256,)\n",
      "dec.8x8_block3.conv1.weight: (256, 256, 3, 3)\n",
      "dec.8x8_block3.conv1.bias: (256,)\n",
      "dec.8x8_block3.skip.weight: (256, 512, 1, 1)\n",
      "dec.8x8_block3.skip.bias: (256,)\n",
      "dec.8x8_block4.norm0.weight: (512,)\n",
      "dec.8x8_block4.norm0.bias: (512,)\n",
      "dec.8x8_block4.conv0.weight: (256, 512, 3, 3)\n",
      "dec.8x8_block4.conv0.bias: (256,)\n",
      "dec.8x8_block4.affine.weight: (256, 512)\n",
      "dec.8x8_block4.affine.bias: (256,)\n",
      "dec.8x8_block4.norm1.weight: (256,)\n",
      "dec.8x8_block4.norm1.bias: (256,)\n",
      "dec.8x8_block4.conv1.weight: (256, 256, 3, 3)\n",
      "dec.8x8_block4.conv1.bias: (256,)\n",
      "dec.8x8_block4.skip.weight: (256, 512, 1, 1)\n",
      "dec.8x8_block4.skip.bias: (256,)\n",
      "dec.16x16_up.norm0.weight: (256,)\n",
      "dec.16x16_up.norm0.bias: (256,)\n",
      "dec.16x16_up.conv0.weight: (256, 256, 3, 3)\n",
      "dec.16x16_up.conv0.bias: (256,)\n",
      "dec.16x16_up.conv0.resample_filter: (1, 1, 2, 2)\n",
      "dec.16x16_up.affine.weight: (256, 512)\n",
      "dec.16x16_up.affine.bias: (256,)\n",
      "dec.16x16_up.norm1.weight: (256,)\n",
      "dec.16x16_up.norm1.bias: (256,)\n",
      "dec.16x16_up.conv1.weight: (256, 256, 3, 3)\n",
      "dec.16x16_up.conv1.bias: (256,)\n",
      "dec.16x16_up.skip.weight: (256, 256, 1, 1)\n",
      "dec.16x16_up.skip.bias: (256,)\n",
      "dec.16x16_up.skip.resample_filter: (1, 1, 2, 2)\n",
      "dec.16x16_block0.norm0.weight: (512,)\n",
      "dec.16x16_block0.norm0.bias: (512,)\n",
      "dec.16x16_block0.conv0.weight: (256, 512, 3, 3)\n",
      "dec.16x16_block0.conv0.bias: (256,)\n",
      "dec.16x16_block0.affine.weight: (256, 512)\n",
      "dec.16x16_block0.affine.bias: (256,)\n",
      "dec.16x16_block0.norm1.weight: (256,)\n",
      "dec.16x16_block0.norm1.bias: (256,)\n",
      "dec.16x16_block0.conv1.weight: (256, 256, 3, 3)\n",
      "dec.16x16_block0.conv1.bias: (256,)\n",
      "dec.16x16_block0.skip.weight: (256, 512, 1, 1)\n",
      "dec.16x16_block0.skip.bias: (256,)\n",
      "dec.16x16_block1.norm0.weight: (512,)\n",
      "dec.16x16_block1.norm0.bias: (512,)\n",
      "dec.16x16_block1.conv0.weight: (256, 512, 3, 3)\n",
      "dec.16x16_block1.conv0.bias: (256,)\n",
      "dec.16x16_block1.affine.weight: (256, 512)\n",
      "dec.16x16_block1.affine.bias: (256,)\n",
      "dec.16x16_block1.norm1.weight: (256,)\n",
      "dec.16x16_block1.norm1.bias: (256,)\n",
      "dec.16x16_block1.conv1.weight: (256, 256, 3, 3)\n",
      "dec.16x16_block1.conv1.bias: (256,)\n",
      "dec.16x16_block1.skip.weight: (256, 512, 1, 1)\n",
      "dec.16x16_block1.skip.bias: (256,)\n",
      "dec.16x16_block2.norm0.weight: (512,)\n",
      "dec.16x16_block2.norm0.bias: (512,)\n",
      "dec.16x16_block2.conv0.weight: (256, 512, 3, 3)\n",
      "dec.16x16_block2.conv0.bias: (256,)\n",
      "dec.16x16_block2.affine.weight: (256, 512)\n",
      "dec.16x16_block2.affine.bias: (256,)\n",
      "dec.16x16_block2.norm1.weight: (256,)\n",
      "dec.16x16_block2.norm1.bias: (256,)\n",
      "dec.16x16_block2.conv1.weight: (256, 256, 3, 3)\n",
      "dec.16x16_block2.conv1.bias: (256,)\n",
      "dec.16x16_block2.skip.weight: (256, 512, 1, 1)\n",
      "dec.16x16_block2.skip.bias: (256,)\n",
      "dec.16x16_block3.norm0.weight: (512,)\n",
      "dec.16x16_block3.norm0.bias: (512,)\n",
      "dec.16x16_block3.conv0.weight: (256, 512, 3, 3)\n",
      "dec.16x16_block3.conv0.bias: (256,)\n",
      "dec.16x16_block3.affine.weight: (256, 512)\n",
      "dec.16x16_block3.affine.bias: (256,)\n",
      "dec.16x16_block3.norm1.weight: (256,)\n",
      "dec.16x16_block3.norm1.bias: (256,)\n",
      "dec.16x16_block3.conv1.weight: (256, 256, 3, 3)\n",
      "dec.16x16_block3.conv1.bias: (256,)\n",
      "dec.16x16_block3.skip.weight: (256, 512, 1, 1)\n",
      "dec.16x16_block3.skip.bias: (256,)\n",
      "dec.16x16_block4.norm0.weight: (512,)\n",
      "dec.16x16_block4.norm0.bias: (512,)\n",
      "dec.16x16_block4.conv0.weight: (256, 512, 3, 3)\n",
      "dec.16x16_block4.conv0.bias: (256,)\n",
      "dec.16x16_block4.affine.weight: (256, 512)\n",
      "dec.16x16_block4.affine.bias: (256,)\n",
      "dec.16x16_block4.norm1.weight: (256,)\n",
      "dec.16x16_block4.norm1.bias: (256,)\n",
      "dec.16x16_block4.conv1.weight: (256, 256, 3, 3)\n",
      "dec.16x16_block4.conv1.bias: (256,)\n",
      "dec.16x16_block4.skip.weight: (256, 512, 1, 1)\n",
      "dec.16x16_block4.skip.bias: (256,)\n",
      "dec.16x16_block4.norm2.weight: (256,)\n",
      "dec.16x16_block4.norm2.bias: (256,)\n",
      "dec.16x16_block4.qkv.weight: (768, 256, 1, 1)\n",
      "dec.16x16_block4.qkv.bias: (768,)\n",
      "dec.16x16_block4.proj.weight: (256, 256, 1, 1)\n",
      "dec.16x16_block4.proj.bias: (256,)\n",
      "dec.32x32_up.norm0.weight: (256,)\n",
      "dec.32x32_up.norm0.bias: (256,)\n",
      "dec.32x32_up.conv0.weight: (256, 256, 3, 3)\n",
      "dec.32x32_up.conv0.bias: (256,)\n",
      "dec.32x32_up.conv0.resample_filter: (1, 1, 2, 2)\n",
      "dec.32x32_up.affine.weight: (256, 512)\n",
      "dec.32x32_up.affine.bias: (256,)\n",
      "dec.32x32_up.norm1.weight: (256,)\n",
      "dec.32x32_up.norm1.bias: (256,)\n",
      "dec.32x32_up.conv1.weight: (256, 256, 3, 3)\n",
      "dec.32x32_up.conv1.bias: (256,)\n",
      "dec.32x32_up.skip.weight: (256, 256, 1, 1)\n",
      "dec.32x32_up.skip.bias: (256,)\n",
      "dec.32x32_up.skip.resample_filter: (1, 1, 2, 2)\n",
      "dec.32x32_block0.norm0.weight: (512,)\n",
      "dec.32x32_block0.norm0.bias: (512,)\n",
      "dec.32x32_block0.conv0.weight: (256, 512, 3, 3)\n",
      "dec.32x32_block0.conv0.bias: (256,)\n",
      "dec.32x32_block0.affine.weight: (256, 512)\n",
      "dec.32x32_block0.affine.bias: (256,)\n",
      "dec.32x32_block0.norm1.weight: (256,)\n",
      "dec.32x32_block0.norm1.bias: (256,)\n",
      "dec.32x32_block0.conv1.weight: (256, 256, 3, 3)\n",
      "dec.32x32_block0.conv1.bias: (256,)\n",
      "dec.32x32_block0.skip.weight: (256, 512, 1, 1)\n",
      "dec.32x32_block0.skip.bias: (256,)\n",
      "dec.32x32_block1.norm0.weight: (512,)\n",
      "dec.32x32_block1.norm0.bias: (512,)\n",
      "dec.32x32_block1.conv0.weight: (256, 512, 3, 3)\n",
      "dec.32x32_block1.conv0.bias: (256,)\n",
      "dec.32x32_block1.affine.weight: (256, 512)\n",
      "dec.32x32_block1.affine.bias: (256,)\n",
      "dec.32x32_block1.norm1.weight: (256,)\n",
      "dec.32x32_block1.norm1.bias: (256,)\n",
      "dec.32x32_block1.conv1.weight: (256, 256, 3, 3)\n",
      "dec.32x32_block1.conv1.bias: (256,)\n",
      "dec.32x32_block1.skip.weight: (256, 512, 1, 1)\n",
      "dec.32x32_block1.skip.bias: (256,)\n",
      "dec.32x32_block2.norm0.weight: (512,)\n",
      "dec.32x32_block2.norm0.bias: (512,)\n",
      "dec.32x32_block2.conv0.weight: (256, 512, 3, 3)\n",
      "dec.32x32_block2.conv0.bias: (256,)\n",
      "dec.32x32_block2.affine.weight: (256, 512)\n",
      "dec.32x32_block2.affine.bias: (256,)\n",
      "dec.32x32_block2.norm1.weight: (256,)\n",
      "dec.32x32_block2.norm1.bias: (256,)\n",
      "dec.32x32_block2.conv1.weight: (256, 256, 3, 3)\n",
      "dec.32x32_block2.conv1.bias: (256,)\n",
      "dec.32x32_block2.skip.weight: (256, 512, 1, 1)\n",
      "dec.32x32_block2.skip.bias: (256,)\n",
      "dec.32x32_block3.norm0.weight: (512,)\n",
      "dec.32x32_block3.norm0.bias: (512,)\n",
      "dec.32x32_block3.conv0.weight: (256, 512, 3, 3)\n",
      "dec.32x32_block3.conv0.bias: (256,)\n",
      "dec.32x32_block3.affine.weight: (256, 512)\n",
      "dec.32x32_block3.affine.bias: (256,)\n",
      "dec.32x32_block3.norm1.weight: (256,)\n",
      "dec.32x32_block3.norm1.bias: (256,)\n",
      "dec.32x32_block3.conv1.weight: (256, 256, 3, 3)\n",
      "dec.32x32_block3.conv1.bias: (256,)\n",
      "dec.32x32_block3.skip.weight: (256, 512, 1, 1)\n",
      "dec.32x32_block3.skip.bias: (256,)\n",
      "dec.32x32_block4.norm0.weight: (384,)\n",
      "dec.32x32_block4.norm0.bias: (384,)\n",
      "dec.32x32_block4.conv0.weight: (256, 384, 3, 3)\n",
      "dec.32x32_block4.conv0.bias: (256,)\n",
      "dec.32x32_block4.affine.weight: (256, 512)\n",
      "dec.32x32_block4.affine.bias: (256,)\n",
      "dec.32x32_block4.norm1.weight: (256,)\n",
      "dec.32x32_block4.norm1.bias: (256,)\n",
      "dec.32x32_block4.conv1.weight: (256, 256, 3, 3)\n",
      "dec.32x32_block4.conv1.bias: (256,)\n",
      "dec.32x32_block4.skip.weight: (256, 384, 1, 1)\n",
      "dec.32x32_block4.skip.bias: (256,)\n",
      "dec.32x32_aux_norm.weight: (256,)\n",
      "dec.32x32_aux_norm.bias: (256,)\n",
      "dec.32x32_aux_conv.weight: (3, 256, 3, 3)\n",
      "dec.32x32_aux_conv.bias: (3,)\n"
     ]
    }
   ],
   "source": [
    "# Print the state_dict of the model inside the loaded pickle\n",
    "state_dict = data['ema'].model.state_dict()\n",
    "print(\"Model state_dict keys and tensor shapes:\")\n",
    "for name, tensor in state_dict.items():\n",
    "    print(f\"{name}: {tuple(tensor.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222d3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
