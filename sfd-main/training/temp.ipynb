{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Parameters:\n",
      "dataset_name: cifar10\n",
      "model_path: None\n",
      "guidance_type: None\n",
      "guidance_rate: 0.0\n",
      "device: cpu\n",
      "is_second_stage: False\n",
      "num_repeats: 4\n",
      "Model already exists: ../training/src/cifar10/edm-cifar10-32x32-uncond-vp.pkl\n",
      "Loading the pre-trained diffusion model from \"../training/src/cifar10/edm-cifar10-32x32-uncond-vp.pkl\"...\n",
      "model.dec.32x32_aux_conv LASTLASYER\n",
      "calling tilingg\n",
      "calling tilingg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import dnnlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import autocast\n",
    "from torch_utils import distributed as dist\n",
    "from torch_utils import training_stats\n",
    "from torch_utils import misc\n",
    "from solver_utils import get_schedule\n",
    "from models.ldm.util import instantiate_from_config\n",
    "from torch_utils.download_util import check_file_by_key\n",
    "\n",
    "\n",
    "def create_model(dataset_name=None, model_path=None, guidance_type=None, guidance_rate=None, device=None, is_second_stage=False, num_repeats=4):\n",
    "    print(\"Function Parameters:\")\n",
    "    for key, value in locals().items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    net_student = None\n",
    "    if is_second_stage: # for second-stage distillation\n",
    "        assert model_path is not None\n",
    "        dist.print0(f'Loading the second-stage teacher model from \"{model_path}\"...')\n",
    "        with dnnlib.util.open_url(model_path, verbose=(dist.get_rank() == 0)) as f:\n",
    "            net = pickle.load(f)['model'].to(device)\n",
    "        model_source = 'edm' if dataset_name in ['cifar10', 'ffhq', 'afhqv2', 'imagenet64'] else 'ldm'\n",
    "        return net, model_source\n",
    "\n",
    "    if model_path is None:\n",
    "        model_path, _ = check_file_by_key(dataset_name)\n",
    "    dist.print0(f'Loading the pre-trained diffusion model from \"{model_path}\"...')\n",
    "    if dataset_name in ['cifar10', 'ffhq', 'afhqv2', 'imagenet64']:         # models from EDM\n",
    "        with dnnlib.util.open_url(model_path, verbose=(dist.get_rank() == 0)) as f:\n",
    "            net_temp = pickle.load(f)['ema'].to(device)\n",
    "        network_kwargs = dnnlib.EasyDict()\n",
    "        if dataset_name in ['cifar10']:\n",
    "            network_kwargs.update(model_type='SongUNet', embedding_type='positional', encoder_type='standard', decoder_type='standard')\n",
    "            network_kwargs.update(channel_mult_noise=1, resample_filter=[1,1], model_channels=128, channel_mult=[2,2,2])\n",
    "            network_kwargs.update(dropout=0.13, use_fp16=False)\n",
    "            network_kwargs.augment_dim = 9\n",
    "            interface_kwargs = dict(img_resolution=32, img_channels=3, label_dim=0)\n",
    "        elif dataset_name in ['ffhq', 'afhqv2']:\n",
    "            network_kwargs.update(model_type='SongUNet', embedding_type='positional', encoder_type='standard', decoder_type='standard')\n",
    "            network_kwargs.update(channel_mult_noise=1, resample_filter=[1,1], model_channels=128, channel_mult=[1,2,2,2])\n",
    "            network_kwargs.update(dropout=0.05, use_fp16=False)\n",
    "            network_kwargs.augment_dim = 9\n",
    "            interface_kwargs = dict(img_resolution=64, img_channels=3, label_dim=0)\n",
    "        else:\n",
    "            network_kwargs.update(model_type='DhariwalUNet', model_channels=192, channel_mult=[1,2,3,4])\n",
    "            interface_kwargs = dict(img_resolution=64, img_channels=3, label_dim=1000)\n",
    "            \n",
    "        network_kwargs.class_name = 'models.networks_edm.EDMPrecond'\n",
    "        net = dnnlib.util.construct_class_by_name(**network_kwargs, **interface_kwargs) # subclass of torch.nn.Module\n",
    "        net.to(device)\n",
    "        net.load_state_dict(net_temp.state_dict(), strict=False)\n",
    "        key_names = list(net.model.state_dict().keys())\n",
    "\n",
    "        # Save to a text file\n",
    "        with open(\"model_keys.txt\", \"w\") as f:\n",
    "            for key in key_names:\n",
    "                f.write(key + \"\\n\")\n",
    "        network_kwargs.update(repeat=num_repeats)\n",
    "        net_student = dnnlib.util.construct_class_by_name(**network_kwargs, **interface_kwargs)\n",
    "        net_student.to(device)\n",
    "        net_student.load_state_dict(net_temp.state_dict(), strict=False)\n",
    "\n",
    "        del net_temp\n",
    "\n",
    "        net.sigma_min = 0.006\n",
    "        net.sigma_max = 80.0\n",
    "        net_student.sigma_min = 0.006\n",
    "        net_student.sigma_max = 80.0\n",
    "        model_source = 'edm'\n",
    "    elif dataset_name in ['lsun_bedroom_ldm', 'ffhq_ldm', 'ms_coco']:   # models from LDM\n",
    "        from omegaconf import OmegaConf\n",
    "        from models.networks_edm import CFGPrecond\n",
    "        if dataset_name in ['lsun_bedroom_ldm']:\n",
    "            assert guidance_type == 'uncond'\n",
    "            config = OmegaConf.load('./models/ldm/configs/latent-diffusion/lsun_bedrooms-ldm-vq-4.yaml')\n",
    "            net = load_ldm_model(config, model_path)\n",
    "            net = CFGPrecond(net, img_resolution=64, img_channels=3, guidance_rate=1., guidance_type='uncond', label_dim=0).to(device)\n",
    "            net.sigma_min = 0.006\n",
    "        elif dataset_name in ['ffhq_ldm']:\n",
    "            assert guidance_type == 'uncond'\n",
    "            config = OmegaConf.load('./models/ldm/configs/latent-diffusion/ffhq-ldm-vq-4.yaml')\n",
    "            net = load_ldm_model(config, model_path)\n",
    "            net = CFGPrecond(net, img_resolution=64, img_channels=3, guidance_rate=1., guidance_type='uncond', label_dim=0).to(device)\n",
    "            net.sigma_min = 0.006\n",
    "        elif dataset_name in ['ms_coco']:\n",
    "            assert guidance_type == 'cfg'\n",
    "            config = OmegaConf.load('./models/ldm/configs/stable-diffusion/v1-inference.yaml')\n",
    "            net = load_ldm_model(config, model_path)\n",
    "            net = CFGPrecond(net, img_resolution=64, img_channels=4, guidance_rate=guidance_rate, guidance_type='classifier-free', label_dim=True).to(device)\n",
    "            net.sigma_min = 0.1\n",
    "        model_source = 'ldm'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset_name: {dataset_name}\")\n",
    "    \n",
    "    return net, net_student, model_source\n",
    "\n",
    "\n",
    "\n",
    "net_copy, net, model_source = create_model(\"cifar10\", None, None, 0.0, \"cpu\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(EDMPrecond(\n",
       "   (model): SongUNet(\n",
       "     (map_noise): PositionalEmbedding()\n",
       "     (map_augment): Linear()\n",
       "     (map_layer0): Linear()\n",
       "     (map_layer1): Linear()\n",
       "     (map_step): PositionalEmbedding()\n",
       "     (map_step_layer0): Linear()\n",
       "     (map_step_layer1): Linear()\n",
       "     (enc): ModuleDict(\n",
       "       (32x32_conv): Conv2d()\n",
       "       (32x32_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (32x32_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (32x32_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (16x16_down): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (16x16_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (16x16_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (16x16_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (8x8_down): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "     )\n",
       "     (dec): ModuleDict(\n",
       "       (8x8_in0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (8x8_in1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block4): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_up): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block4): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (32x32_up): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block4): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_aux_norm): GroupNorm()\n",
       "       (32x32_aux_conv): Conv2d()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " EDMPrecond(\n",
       "   (model): SongUNet(\n",
       "     (map_noise): PositionalEmbedding()\n",
       "     (map_augment): Linear()\n",
       "     (map_layer0): Linear()\n",
       "     (map_layer1): Linear()\n",
       "     (map_step): PositionalEmbedding()\n",
       "     (map_step_layer0): Linear()\n",
       "     (map_step_layer1): Linear()\n",
       "     (enc): ModuleDict(\n",
       "       (32x32_conv): Conv2d()\n",
       "       (32x32_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (32x32_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (32x32_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (16x16_down): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (16x16_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (16x16_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (16x16_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (8x8_down): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "     )\n",
       "     (dec): ModuleDict(\n",
       "       (8x8_in0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (8x8_in1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "       )\n",
       "       (8x8_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (8x8_block4): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_up): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (16x16_block4): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "         (norm2): GroupNorm()\n",
       "         (qkv): Conv2d()\n",
       "         (proj): Conv2d()\n",
       "       )\n",
       "       (32x32_up): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block0): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block1): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block2): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block3): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_block4): UNetBlock(\n",
       "         (norm0): GroupNorm()\n",
       "         (conv0): Conv2d()\n",
       "         (affine): Linear()\n",
       "         (norm1): GroupNorm()\n",
       "         (conv1): Conv2d()\n",
       "         (affine_step): Linear()\n",
       "         (skip): Conv2d()\n",
       "       )\n",
       "       (32x32_aux_norm): GroupNorm()\n",
       "       (32x32_aux_conv): Conv2d()\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_copy.eval(),net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_denoised(net, x, t, class_labels=None, condition=None, unconditional_condition=None, step_condition=None):\n",
    "    if hasattr(net, 'guidance_type'):       # models from LDM and Stable Diffusion\n",
    "        denoised = net(x, t, class_labels=class_labels, condition=condition, unconditional_condition=unconditional_condition, step_condition=step_condition)\n",
    "    elif hasattr(net, 'module') and hasattr(net.module, 'guidance_type'):       # for training: models from LDM and Stable Diffusion\n",
    "        denoised = net(x, t, class_labels=class_labels, condition=condition, unconditional_condition=unconditional_condition, step_condition=step_condition)\n",
    "    else:\n",
    "        print(\"calling\")\n",
    "        denoised = net(x, t, class_labels=class_labels, step_condition=step_condition)\n",
    "    return denoised\n",
    "\n",
    "# Model config\n",
    "img_resolution = 32\n",
    "img_channels = 3\n",
    "label_dim = 10\n",
    "\n",
    "\n",
    "# Dummy input\n",
    "B = 2\n",
    "x = torch.randn(B, img_channels, img_resolution, img_resolution)\n",
    "sigma = torch.full((B,), 1.0)  # constant noise level\n",
    "class_labels = torch.zeros(B, label_dim)  # zero dummy labels\n",
    "# step_condition = torch.full((B,), 7.0)    # constant step for conditioning\n",
    "step_condition = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 12, 32, 32])\n",
      "calling\n",
      "calling\n",
      "calling\n",
      "Output shape: torch.Size([2, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Run dummy forward\n",
    "out_stu_1 = get_denoised(net, x, sigma, class_labels=class_labels, step_condition=step_condition)\n",
    "\n",
    "print(\"Output shape:\", out_stu_1.shape)\n",
    "# Run dummy forward\n",
    "out_teacher_1 = get_denoised(net_copy, x, sigma, class_labels=class_labels, step_condition=step_condition)\n",
    "out_teacher_2 = get_denoised(net_copy, x, sigma, class_labels=class_labels, step_condition=step_condition)\n",
    "out_teacher_3 = get_denoised(net_copy, x, sigma, class_labels=class_labels, step_condition=step_condition)\n",
    "\n",
    "print(\"Output shape:\", out_teacher_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out_teacher_1-out_teacher_2).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((out_stu_1[:,0:3] - out_teacher_1).mean())\n",
    "print((out_stu_1[:,3:6] - out_teacher_1).mean())\n",
    "print((out_stu_1[:,6:9] - out_teacher_1).mean())\n",
    "print((out_stu_1[:,9:12] - out_teacher_1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assigned:\n",
      "  orig -> dec.32x32_aux_conv.weight (torch.Size([3, 256, 3, 3]))\n",
      "  tiled -> dec.32x32_aux_conv.weight (torch.Size([3, 256, 3, 3]))\n",
      "\n",
      "Assigned:\n",
      "  orig -> dec.32x32_aux_conv.bias (torch.Size([3]))\n",
      "  tiled -> dec.32x32_aux_conv.bias (torch.Size([3]))\n"
     ]
    }
   ],
   "source": [
    "model = net.model\n",
    "model_orig = net_copy.model\n",
    "\n",
    "\n",
    "# Get last layer prefix (e.g., 'dec.32x32_aux_conv')\n",
    "last_layer_prefix = model.last_layer.replace('model.', '')\n",
    "\n",
    "# Collect weights and biases\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(last_layer_prefix):\n",
    "        orig = dict(model_orig.named_parameters())[name]\n",
    "        tiled = param\n",
    "        print(f\"\\nAssigned:\\n  orig -> {name} ({orig.shape})\\n  tiled -> {name} ({tiled.shape})\")\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tiled[0:3]-orig).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand(3,256,32,32)\n",
    "b = a.repeat(4,1,1,1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b[4:7]-a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.shape)         # torch.Size([12, 256, 32, 32])\n",
    "print((b[0] == a).all())  # Should be True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/_weights_only_unpickler.py:549: UserWarning: Detected pickle protocol 4 in the checkpoint, which was not the default pickle protocol used by `torch.load` (2). The weights_only Unpickler might not support all instructions implemented by this protocol, please file an issue for adding support if you encounter this.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/teamspace/studios/this_studio/sfd-main/euler_sampler_logs_tensor([0]).pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/torch/serialization.py:1548\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[1;32m   1542\u001b[0m             opened_file,\n\u001b[1;32m   1543\u001b[0m             map_location,\n\u001b[1;32m   1544\u001b[0m             _weights_only_unpickler,\n\u001b[1;32m   1545\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[1;32m   1546\u001b[0m         )\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1548\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(\n\u001b[1;32m   1550\u001b[0m     opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args\n\u001b[1;32m   1551\u001b[0m )\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\nPlease file an issue with the following so that we can make `weights_only=True` compatible with your use case: WeightsUnpickler error: Unsupported operand 149\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
